{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 1. 2. 1. 1. 1. 2. 2. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 1. 2.\n",
      " 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 2. 1. 1. 1. 1. 2. 1. 2. 1. 2. 2. 1. 1. 1. 1. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
      " 1. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 1.\n",
      " 1. 2. 1. 2. 2. 1. 1. 1. 1. 2. 1. 2. 1. 2. 1. 1. 1. 2. 1. 2. 2. 1. 1. 1.\n",
      " 1. 1. 2. 1. 1. 1. 2. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 2. 2. 1. 2. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 2. 1. 2.\n",
      " 2. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2.\n",
      " 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 1. 2. 1. 1. 2. 2. 1. 2. 1. 1. 1. 1. 1.\n",
      " 2. 1. 2. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 2. 1. 1.\n",
      " 2. 2. 1. 1. 1. 2. 1. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 2. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 2.\n",
      " 1. 1. 1. 2. 2. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 1. 2. 1.\n",
      " 1. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 2. 2.\n",
      " 1. 1. 2. 1. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 2. 1. 1. 2. 2. 2.\n",
      " 1. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2.\n",
      " 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 2. 1. 1. 1. 2. 1. 2. 2. 2.\n",
      " 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 1. 2. 2. 1. 1. 2. 2. 2.\n",
      " 1. 1. 1. 2. 2. 2. 1. 2. 1. 2. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 2. 1. 2. 1. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
      " 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 1. 2. 1. 1. 2. 1. 1. 2. 1. 1.\n",
      " 1. 1. 2. 2. 2. 1. 1. 1. 1. 2. 2. 1. 2. 2. 1. 1. 2. 2. 1. 1. 1. 2. 2. 1.\n",
      " 1. 2. 1. 2. 2. 1. 1. 2. 1. 1. 2. 1. 2. 2. 1. 2. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# iris\n",
    "# wine\n",
    "name = \"breast-cancer-wisconsin.txt\"\n",
    "# breast-cancer-wisconsin\n",
    "data = np.loadtxt(name)\n",
    "\n",
    "# split 最後的class\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "#測試分集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#參數設定\n",
    "max_iter = 100000\n",
    "learning_rate = 0.01\n",
    "neurons_per_layer = (15, 10,5)\n",
    "initial_weight_scale = 1.0\n",
    "\n",
    "# 初始化新的 MLPClassifier 物件\n",
    "mlp = MLPClassifier(hidden_layer_sizes=neurons_per_layer, max_iter=1, learning_rate_init=learning_rate,\n",
    "                    random_state=42, warm_start=True)\n",
    "\n",
    "# 儲存每個迭代的 training accuracy\n",
    "train_accuracies = []\n",
    "\n",
    "# 訓練模型\n",
    "for i in range(max_iter):\n",
    "    mlp.max_iter += 1\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    # 每 1000 次迭代記錄一次 training accuracy\n",
    "    if i % 10000 == 0:\n",
    "        train_accuracy = mlp.score(X_train, y_train)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        print(f\"Iteration {i}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "# 在測試集上進行預測\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# 打印測試集上的 accuracy\n",
    "test_accuracy = mlp.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 繪製 training curve\n",
    "plt.plot(train_accuracies)\n",
    "plt.title(f'{name} Training Accuracy Curve')\n",
    "plt.xlabel('Iterations (every 10000 iterations)')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tpema\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tpema\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tpema\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tpema\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tpema\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tpema\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (7) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tpema\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Training Accuracy: 0.4014084507042254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tpema\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1728) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10000, Training Accuracy: 0.9577464788732394\n",
      "Iteration 20000, Training Accuracy: 0.9577464788732394\n",
      "Iteration 30000, Training Accuracy: 0.9577464788732394\n",
      "Iteration 40000, Training Accuracy: 0.9577464788732394\n",
      "Iteration 50000, Training Accuracy: 0.9577464788732394\n",
      "Iteration 60000, Training Accuracy: 0.9577464788732394\n",
      "Iteration 70000, Training Accuracy: 0.9577464788732394\n",
      "Iteration 80000, Training Accuracy: 0.9577464788732394\n",
      "Iteration 90000, Training Accuracy: 0.9577464788732394\n",
      "Test Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# iris\n",
    "# wine\n",
    "# breast-cancer-wisconsin\n",
    "data = np.loadtxt('wine.txt')\n",
    "\n",
    "# split 最後的class\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "#測試分集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#參數設定\n",
    "max_iter = 100000\n",
    "learning_rate = 0.001\n",
    "neurons_per_layer = (10, 5)\n",
    "initial_weight_scale = 1.0\n",
    "\n",
    "# 使用momentum\n",
    "mlp = MLPClassifier(hidden_layer_sizes=neurons_per_layer, max_iter=1, learning_rate_init=learning_rate,\n",
    "                    momentum=0.9, random_state=42, warm_start=True)\n",
    "\n",
    "\n",
    "# 儲存每個迭代的 training accuracy\n",
    "train_accuracies = []\n",
    "\n",
    "# 訓練模型\n",
    "for i in range(max_iter):\n",
    "    mlp.max_iter += 1\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    # 每 1000 次迭代記錄一次 training accuracy\n",
    "    if i % 10000 == 0:\n",
    "        train_accuracy = mlp.score(X_train, y_train)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        print(f\"Iteration {i}, Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "# 在測試集上進行預測\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# 打印測試集上的 accuracy\n",
    "test_accuracy = mlp.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 繪製 training curve\n",
    "plt.plot(train_accuracies)\n",
    "plt.title('Training Accuracy Curve')\n",
    "plt.xlabel('Iterations (every 10000 iterations)')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2368 - accuracy: 0.6099\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.9221 - accuracy: 0.6374\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 781us/step - loss: 0.6847 - accuracy: 0.6465\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 805us/step - loss: 0.4940 - accuracy: 0.6557\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 808us/step - loss: 0.3408 - accuracy: 0.6648\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.2174 - accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 806us/step - loss: 0.1174 - accuracy: 0.6685\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.0323 - accuracy: 0.6685\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 837us/step - loss: -0.0485 - accuracy: 0.6685\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 953us/step - loss: -0.1327 - accuracy: 0.6685\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 748us/step - loss: -0.2276 - accuracy: 0.6685\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 892us/step - loss: -0.3300 - accuracy: 0.6685\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 722us/step - loss: -0.4453 - accuracy: 0.6685\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 809us/step - loss: -0.5827 - accuracy: 0.6685\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 835us/step - loss: -0.7313 - accuracy: 0.6685\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 920us/step - loss: -0.9080 - accuracy: 0.6685\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 809us/step - loss: -1.0955 - accuracy: 0.6685\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 780us/step - loss: -1.2923 - accuracy: 0.6685\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 782us/step - loss: -1.5197 - accuracy: 0.6685\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 807us/step - loss: -1.7697 - accuracy: 0.6685\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 691us/step - loss: -2.0516 - accuracy: 0.6685\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 749us/step - loss: -2.3442 - accuracy: 0.6685\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 841us/step - loss: -2.7156 - accuracy: 0.6685\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -3.1176 - accuracy: 0.6685\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -3.6363 - accuracy: 0.6685\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 841us/step - loss: -4.2551 - accuracy: 0.6685\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 897us/step - loss: -4.9361 - accuracy: 0.6685\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 748us/step - loss: -5.6451 - accuracy: 0.6685\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: -6.4583 - accuracy: 0.6685\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 877us/step - loss: -7.3140 - accuracy: 0.6685\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 876us/step - loss: -8.2995 - accuracy: 0.6685\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 916us/step - loss: -9.3049 - accuracy: 0.6685\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 864us/step - loss: -10.4400 - accuracy: 0.6685\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -11.5687 - accuracy: 0.6685\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 957us/step - loss: -12.8619 - accuracy: 0.6685\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 809us/step - loss: -14.1568 - accuracy: 0.6685\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 855us/step - loss: -15.5837 - accuracy: 0.6685\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -17.0960 - accuracy: 0.6685\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 896us/step - loss: -18.7521 - accuracy: 0.6685\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 641us/step - loss: -20.4305 - accuracy: 0.6685\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 723us/step - loss: -22.3319 - accuracy: 0.6685\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 691us/step - loss: -24.2496 - accuracy: 0.6685\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 690us/step - loss: -26.3931 - accuracy: 0.6685\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 723us/step - loss: -28.6536 - accuracy: 0.6685\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 636us/step - loss: -31.0154 - accuracy: 0.6685\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 664us/step - loss: -33.4032 - accuracy: 0.6685\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 694us/step - loss: -35.7934 - accuracy: 0.6685\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 724us/step - loss: -38.5238 - accuracy: 0.6685\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -41.2883 - accuracy: 0.6685\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 805us/step - loss: -44.2920 - accuracy: 0.6685\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -47.4151 - accuracy: 0.6685\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 953us/step - loss: -50.6279 - accuracy: 0.6685\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 806us/step - loss: -53.6783 - accuracy: 0.6685\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 978us/step - loss: -56.9860 - accuracy: 0.6685\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -59.9524 - accuracy: 0.6685\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -63.6265 - accuracy: 0.6685\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -67.2665 - accuracy: 0.6685\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -71.1469 - accuracy: 0.6685\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: -75.2612 - accuracy: 0.6685\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: -79.7924 - accuracy: 0.6685\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -84.4529 - accuracy: 0.6685\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -89.1255 - accuracy: 0.6685\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -94.0278 - accuracy: 0.6685\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -99.1094 - accuracy: 0.6685\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -104.3837 - accuracy: 0.6685\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -109.8811 - accuracy: 0.6685\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 837us/step - loss: -115.6762 - accuracy: 0.6685\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 809us/step - loss: -121.2042 - accuracy: 0.6685\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -127.2507 - accuracy: 0.6685\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 894us/step - loss: -133.1217 - accuracy: 0.6685\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 894us/step - loss: -139.6813 - accuracy: 0.6685\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 920us/step - loss: -146.3345 - accuracy: 0.6685\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 778us/step - loss: -152.8760 - accuracy: 0.6685\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 839us/step - loss: -159.7094 - accuracy: 0.6685\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -167.0240 - accuracy: 0.6685\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 899us/step - loss: -173.9356 - accuracy: 0.6685\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 837us/step - loss: -181.3444 - accuracy: 0.6685\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 806us/step - loss: -189.5474 - accuracy: 0.6685\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 977us/step - loss: -197.1497 - accuracy: 0.6685\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 893us/step - loss: -205.4872 - accuracy: 0.6685\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 953us/step - loss: -213.9204 - accuracy: 0.6685\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 805us/step - loss: -222.2310 - accuracy: 0.6685\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -231.2057 - accuracy: 0.6685\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 950us/step - loss: -240.2496 - accuracy: 0.6685\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 806us/step - loss: -248.9687 - accuracy: 0.6685\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 841us/step - loss: -258.2925 - accuracy: 0.6685\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 755us/step - loss: -267.4745 - accuracy: 0.6685\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 665us/step - loss: -277.5159 - accuracy: 0.6685\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 663us/step - loss: -287.7052 - accuracy: 0.6685\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 638us/step - loss: -297.4420 - accuracy: 0.6685\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 665us/step - loss: -308.1546 - accuracy: 0.6685\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 749us/step - loss: -318.6833 - accuracy: 0.6685\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 815us/step - loss: -329.7885 - accuracy: 0.6685\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -341.3689 - accuracy: 0.6685\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 979us/step - loss: -352.4187 - accuracy: 0.6685\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 960us/step - loss: -363.0984 - accuracy: 0.6685\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 867us/step - loss: -375.4361 - accuracy: 0.6685\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -387.2074 - accuracy: 0.6685\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 893us/step - loss: -397.6060 - accuracy: 0.6685\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 866us/step - loss: -410.2581 - accuracy: 0.6685\n",
      "5/5 [==============================] - 0s 870us/step\n",
      "Test Accuracy: 0.5766423357664233\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# 加載數據\n",
    "data = np.loadtxt('breast-cancer-wisconsin.txt')\n",
    "\n",
    "# 分割特徵和標籤\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# 對特徵進行標準化\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 分割數據集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定義Keras模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=10, activation='relu', input_dim=X_train.shape[1]),\n",
    "    tf.keras.layers.Dense(units=5, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 使用Rprop優化器\n",
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(X_train, y_train, epochs=100000, batch_size=32, verbose=1)\n",
    "\n",
    "# 在測試集上進行預測\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# 計算測試準確率\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '14.23\\t1.71\\t2.43\\t15.6\\t127\\t2.8\\t3.06\\t0.28\\t2.29\\t5.64\\t1.04\\t3.92\\t1065\\t1' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tpema\\Downloads\\類神經網路\\HW2.ipynb 儲存格 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tpema/Downloads/%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/HW2.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m train_data, test_data\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tpema/Downloads/%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/HW2.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Load data from CSV\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tpema/Downloads/%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/HW2.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\u001b[39m'\u001b[39;49m\u001b[39mwine.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tpema/Downloads/%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/HW2.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# split 最後的class\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tpema/Downloads/%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/HW2.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X \u001b[39m=\u001b[39m data[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\npyio.py:1356\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1354\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1356\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[0;32m   1357\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m   1358\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   1359\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[0;32m   1361\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\npyio.py:999\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    996\u001b[0m     data \u001b[39m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m    998\u001b[0m \u001b[39mif\u001b[39;00m read_dtype_via_object_chunks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 999\u001b[0m     arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[0;32m   1000\u001b[0m         data, delimiter\u001b[39m=\u001b[39;49mdelimiter, comment\u001b[39m=\u001b[39;49mcomment, quote\u001b[39m=\u001b[39;49mquote,\n\u001b[0;32m   1001\u001b[0m         imaginary_unit\u001b[39m=\u001b[39;49mimaginary_unit,\n\u001b[0;32m   1002\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols, skiplines\u001b[39m=\u001b[39;49mskiplines, max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[0;32m   1003\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1004\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding, filelike\u001b[39m=\u001b[39;49mfilelike,\n\u001b[0;32m   1005\u001b[0m         byte_converters\u001b[39m=\u001b[39;49mbyte_converters)\n\u001b[0;32m   1007\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1008\u001b[0m     \u001b[39m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m     \u001b[39m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[39m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[39m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     \u001b[39mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string '14.23\\t1.71\\t2.43\\t15.6\\t127\\t2.8\\t3.06\\t0.28\\t2.29\\t5.64\\t1.04\\t3.92\\t1065\\t1' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def custom_train_test_split(data, test_size=0.2):\n",
    "    np.random.shuffle(data)  # 隨機打亂資料順序\n",
    "    split_idx = int(len(data) * (1 - test_size))\n",
    "    train_data = data[:split_idx]\n",
    "    test_data = data[split_idx:]\n",
    "    return train_data, test_data\n",
    "\n",
    "# Load data from CSV\n",
    "data = np.loadtxt('wine.txt', delimiter=',')\n",
    "\n",
    "# split 最後的class\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "#測試分集\n",
    "X_train, X_test, y_train, y_test = custom_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定義激活函數 sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 初始化權重和偏差\n",
    "def initialize_parameters(input_size, hidden_sizes, output_size):\n",
    "    layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    parameters = {}\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        parameters['W' + str(i)] = np.random.randn(layer_sizes[i], layer_sizes[i-1]) * 0.01\n",
    "        parameters['b' + str(i)] = np.zeros((layer_sizes[i], 1))\n",
    "    return parameters\n",
    "\n",
    "# 前向傳播\n",
    "def forward_propagation(X, parameters):\n",
    "    caches = []\n",
    "    A = X.T\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(1, L):\n",
    "        Z = np.dot(parameters['W' + str(l)], A) + parameters['b' + str(l)]\n",
    "        A = sigmoid(Z)\n",
    "        caches.append((Z, A))\n",
    "\n",
    "    ZL = np.dot(parameters['W' + str(L)], A) + parameters['b' + str(L)]\n",
    "    AL = sigmoid(ZL)\n",
    "    caches.append((ZL, AL))\n",
    "\n",
    "    return AL, caches\n",
    "\n",
    "# 計算成本（損失函數）\n",
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[0]\n",
    "    cost = -np.sum(Y * np.log(AL) + (1 - Y) * np.log(1 - AL)) / m\n",
    "    return cost\n",
    "\n",
    "# 反向傳播\n",
    "def backward_propagation(AL, Y, caches, parameters):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    dZL = dAL * (AL * (1 - AL))\n",
    "    dWL = np.dot(dZL, caches[L-1][1].T) / Y.shape[0]\n",
    "    dbL = np.sum(dZL, axis=1, keepdims=True) / Y.shape[0]\n",
    "\n",
    "    grads['dW' + str(L)] = dWL\n",
    "    grads['db' + str(L)] = dbL\n",
    "\n",
    "    dA = np.dot(parameters['W' + str(L)].T, dZL)\n",
    "    for l in reversed(range(L-1)):\n",
    "        dZ = dA * (caches[l][1] * (1 - caches[l][1]))\n",
    "        dW = np.dot(dZ, caches[l][0].T) / Y.shape[0]\n",
    "        db = np.sum(dZ, axis=1, keepdims=True) / Y.shape[0]\n",
    "\n",
    "        grads['dW' + str(l + 1)] = dW\n",
    "        grads['db' + str(l + 1)] = db\n",
    "\n",
    "        dA = np.dot(parameters['W' + str(l + 1)].T, dZ)\n",
    "\n",
    "    return grads\n",
    "\n",
    "# 更新權重和偏差\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(L):\n",
    "        parameters['W' + str(l + 1)] -= learning_rate * grads['dW' + str(l + 1)]\n",
    "        parameters['b' + str(l + 1)] -= learning_rate * grads['db' + str(l + 1)]\n",
    "    return parameters\n",
    "\n",
    "# 將目標變成 one-hot 編碼\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    one_hot_labels = np.zeros((len(labels), num_classes))\n",
    "    for i in range(len(labels)):\n",
    "        one_hot_labels[i, int(labels[i])] = 1\n",
    "    return one_hot_labels\n",
    "\n",
    "# 主訓練過程\n",
    "def train_mlp(X_train, y_train, X_test, y_test, hidden_layer_sizes, learning_rate=0.01, epochs=1000):\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = len(np.unique(y_train))\n",
    "    parameters = initialize_parameters(input_size, hidden_layer_sizes, output_size)\n",
    "    costs_train = []\n",
    "    costs_test = []\n",
    "\n",
    "    y_train_encoded = one_hot_encode(y_train, output_size)\n",
    "    y_test_encoded = one_hot_encode(y_test, output_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        AL_train, caches_train = forward_propagation(X_train, parameters)\n",
    "        cost_train = compute_cost(AL_train, y_train_encoded)\n",
    "        grads = backward_propagation(AL_train, y_train_encoded, caches_train, parameters)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        AL_test, _ = forward_propagation(X_test, parameters)\n",
    "        cost_test = compute_cost(AL_test, y_test_encoded)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            costs_train.append(cost_train)\n",
    "            costs_test.append(cost_test)\n",
    "            print(f\"Epoch {epoch}: Train Cost = {cost_train}, Test Cost = {cost_test}\")\n",
    "\n",
    "    return parameters, costs_train, costs_test\n",
    "\n",
    "# 資料預處理（若有必要）\n",
    "# 請注意：資料預處理步驟可能會因資料集而異\n",
    "\n",
    "# 執行訓練\n",
    "hidden_layer_sizes = [15, 10, 5]\n",
    "epochs = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "parameters, costs_train, costs_test = train_mlp(X_train, y_train, X_test, y_test, hidden_layer_sizes, learning_rate, epochs)\n",
    "\n",
    "# 繪製訓練和測試成本曲線\n",
    "plt.plot(costs_train, label='Train Cost')\n",
    "plt.plot(costs_test, label='Test Cost')\n",
    "plt.title('Training and Test Cost')\n",
    "plt.xlabel('Epochs (every 100 iterations)')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 2. 1. 1. 2. 1. 1. 2. 1. 2. 2. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 1. 2. 1. 2. 1. 1. 1. 2. 2. 1. 2. 2. 2. 1.\n",
      " 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 1. 2. 2. 1. 1. 1. 2. 2. 1. 2.\n",
      " 2. 2. 1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 2. 2. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 1. 2. 2. 2. 1. 2. 1. 2. 2. 1. 1. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 1. 2.\n",
      " 2. 1. 1. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 1. 1. 2. 1. 1. 1. 2. 1. 1. 2.\n",
      " 2. 1. 1. 2. 1. 2. 1. 1. 2. 1. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 1. 2. 2. 1.\n",
      " 1. 1. 2. 1. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1.\n",
      " 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2.\n",
      " 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 2. 1. 1.\n",
      " 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1.\n",
      " 1. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1.\n",
      " 2. 2. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1.\n",
      " 1. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2.\n",
      " 1. 1. 1. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 1.\n",
      " 1. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1.\n",
      " 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('breast-cancer-wisconsin.txt')\n",
    "\n",
    "def custom_train_test_split(data, test_size=0.2):\n",
    "\n",
    "    num_samples = len(data)\n",
    "    num_test_samples = int(test_size * num_samples)\n",
    "\n",
    "    X_train = data[num_test_samples:, :-1]  # 特徵欄位\n",
    "    y_train = data[num_test_samples:, -1]   # 分類標籤\n",
    "\n",
    "    X_test = data[:num_test_samples, :-1]\n",
    "    y_test = data[:num_test_samples, -1]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# 使用自訂的函式切分資料集\n",
    "x_train, x_test, y_train, y_test = custom_train_test_split(data, test_size=0.2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
